{"meta":{"title":"Lemonorn Blog","subtitle":"","description":"","author":"Lemonorn","url":"http://example.com","root":"/"},"pages":[],"posts":[{"title":"如何提问","slug":"如何提问","date":"2023-07-23T14:07:56.504Z","updated":"2023-07-27T15:43:13.490Z","comments":true,"path":"2023/如何提问/","link":"","permalink":"http://example.com/2023/%E5%A6%82%E4%BD%95%E6%8F%90%E9%97%AE/","excerpt":"","text":"为什么要问“好的问题”？ 在黑客的世界里，当你拋出一个技术问题时，最终是否能得到有用的回答，往往取决于你所提问和追问的方式。” 这句话我觉得说的很中肯，因为无论是从提问者和被提问者的视角看，都希望提的问题本身是好的。 从被提问者的角度看： 黑客们喜爱有挑战性的问题，或者能激发他们思维的好问题。 可以看出，提问是需要智慧的，因为你能否得到有价值的回答很大程度上取决于你的提问方式，换句话说，取决于被提问者是否愿意尽力给你一个较好的答复。这个说的很好： 绝不要自以为够格得到答案，你没有；你并没有。毕竟你没有为这种服务支付任何报酬。你将会是自己去挣到一个答案，靠提出有内涵的、有趣的、有思维激励作用的问题 —— 一个有潜力能贡献社区经验的问题，而不仅仅是被动地从他人处索取知识。 在哪提问？毋庸置疑，我们遇到问题时才会提问。我个人遇到了问题，第一反应便是google寻找答案，如果没有满意的，我会斟酌一番，在wechat上私信我认为有能力回答我问题的人。我很少在某个论坛或某个网站上通过发帖的方式提问？因为我感觉这种回复往往不够及时，而且，有可能收到回复时，自己已经把提问忘到九霄云外去了。 如果从开源的角度上看，在公开的论坛上提问或许能帮助到很多和你拥有相同问题的人。（我们不就经常通过某些论坛上的回答受益吗？） 国内的社区我不太了解，国外的StackOverflow汇聚了编程的绝大多数问题，你想问的，不说能找到精确的答案，但知道大概率能找到相关的答案。 如何提问？精确地描述问题并言之有物 仔细、清楚地描述你的问题或 Bug 的症状。 描述问题发生的环境（机器配置、操作系统、应用程序、以及相关的信息），提供经销商的发行版和版本号（如：Fedora Core 4、Slackware 9.1等）。 描述在提问前你是怎样去研究和理解这个问题的。 描述在提问前为确定问题而采取的诊断步骤。 描述最近做过什么可能相关的硬件或软件变更。 尽可能地提供一个可以重现这个问题的可控环境的方法。 提问后记得表示感谢，注意表示感谢的方式，使用聪明的方式。如谢谢你的关注、谢谢你的关照要比先谢了、感谢！要好。","categories":[],"tags":[]},{"title":"LU分解与并行计算","slug":"LU分解与并行计算","date":"2023-07-23T14:07:56.503Z","updated":"2023-07-27T15:42:48.050Z","comments":true,"path":"2023/LU分解与并行计算/","link":"","permalink":"http://example.com/2023/LU%E5%88%86%E8%A7%A3%E4%B8%8E%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/","excerpt":"","text":"介绍在线性代数与数值分析中，LU分解是矩阵分解的一种，将一个矩阵分解为一个下三角矩阵和一个上三角矩阵的乘积，有时需要再乘上一个置换矩阵。LU分解可以被视为高斯消元法的矩阵形式。在数值计算上，LU分解经常被用来解线性方程组、且在求逆矩阵和计算行列式中都是一个关键的步骤。 LU矩阵分解是一种常用的矩阵分解方法，用于将一个矩阵分解为一个下三角矩阵L和一个上三角矩阵U的乘积。其原理可以简述如下： 给定一个n×n的矩阵A，LU分解的目标是找到两个矩阵L和U，使得A &#x3D; LU。 首先，我们将矩阵A写成如下形式： A &#x3D; [a11 a12 a13 … a1n][a21 a22 a23 … a2n][a31 a32 a33 … a3n][… … … … …][an1 an2 an3 … ann] 然后，我们通过消元的方式将A分解为L和U。消元过程可以理解为对A进行一系列的行变换，使得A的下三角部分变为0，而上三角部分保持原样。在每一次消元操作中，我们选择一个主元（通常是矩阵的对角线元素），并用它来消除矩阵的其他元素。 消元的过程中，我们通过一系列的行变换将A变换为U，其中U是一个上三角矩阵。行变换包括以下步骤：选择一个主元，将主元所在列的下方元素消为0，重复这个过程直到得到上三角矩阵U。 在消元的过程中，我们记录下所做的行变换，并将其应用到一个单位下三角矩阵上，得到矩阵L。L是一个下三角矩阵，其对角线元素为1。 最终，我们得到了矩阵A的LU分解，即A &#x3D; LU，其中L是一个下三角矩阵，U是一个上三角矩阵。 LU矩阵分解的主要优点是可以减少求解线性方程组的计算量，特别是在需要多次求解相同系数矩阵的线性方程组时。通过LU分解，我们可以将原始的线性方程组转化为两个较简单的方程组，从而更高效地求解解析解或进行数值计算。 接下来，我们用算法来描述这一过程。我们将其分为串行算法和并行算法。介绍完后，我们会比较它们的性能，并在此基础上进行分析。 串行算法思路对于一个 n 阶非奇异方阵 A&#x3D;[aij]，对 A 进行 LU 分解是求一个主对角元素全为 1 的下三 角方阵 L&#x3D;[lij]与上三角方阵 U&#x3D;[uij]，使 A&#x3D;LU。设 A 的各阶主子行列式皆非零，U 和 L 的元 素可由下面的递推式求出： 在计算过程中，首先计算出 U 的第一行元素，然后算出 L 的第一列元素，修改相应 A 的元素；再算出 U 的第二行，L 的第二列…，直至算出 unn 为止。若一次乘法和加法运算或 一次除法运算时间为一个单位时间，则下述 LU 分解的串行算法时间复杂度为O(n^3^): 12345678910111213141516171819202122232425262728293031323334353637void luDecomposition(double** a, double** l, double** u, int n) &#123; /* * LU分解函数 * 参数: * - a: 输入矩阵，n×n的二维数组 * - l: 下三角矩阵，n×n的二维数组，作为输出参数 * - u: 上三角矩阵，n×n的二维数组，作为输出参数 * - n: 矩阵的维度 */ // LU分解的第一步：计算下三角矩阵L和上三角矩阵U for (int k = 0; k &lt; n; k++) &#123; // 计算下三角矩阵L的第k列（不包括对角线元素） for (int i = k + 1; i &lt; n; i++) &#123; a[i][k] = a[i][k] / a[k][k]; // 计算L的元素值 &#125; // 计算上三角矩阵U的第k行和第k列（包括对角线元素） for (int i = k + 1; i &lt; n; i++) &#123; for (int j = k + 1; j &lt; n; j++) &#123; a[i][j] = a[i][j] - a[i][k] * a[k][j]; // 计算U的元素值 &#125; &#125; &#125; // 构建下三角矩阵L和上三角矩阵U for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; if (j &lt; i) &#123; l[i][j] = a[i][j]; // L的元素值为a中对应位置的值 &#125; else &#123; u[i][j] = a[i][j]; // U的元素值为a中对应位置的值 &#125; &#125; l[i][i] = 1.0; // L的对角线元素为1 &#125;&#125; 并行算法思路使用工具我们使用OpenMP来进行并行化计算 实现原理在 LU 分解的过程中，主要的计算是利用主行 i 对其余各行 j，(j&gt;i)作初等行变换，各行 计算之间没有数据相关关系，因此可以对矩阵 A 按行划分来实现并行计算。考虑到在计算 过程中处理器之间的负载均衡，对 A 采用行交叉划分：设处理器个数为 p，矩阵 A 的阶数为 n，m &#x3D; n &#x2F; p，对矩阵 A 行交叉划分后，编号为 i(i&#x3D;0,1,…,p-1)的处理器存有 A 的第 i, i+p,…, i+(m-1)p 行。然后依次以第 0,1,…,n-1 行作为主行，将其广播给所有处理器，各处理器利用 主行对其部分行向量做行变换，这实际上是各处理器轮流选出主行并广播。若以编号为 my_rank 的处理器的第 i 行元素作为主行，并将它广播给所有处理器，则编号大于等于 my_rank 的处理器利用主行元素对其第 i+1,…,m-1 行数据做行变换，其它处理器利用主行元 素对其第 i,…,m-1 行数据做行变换。具体并行算法框架描述如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243void luDecomposition(double *a, double *l, double *u, int n) &#123; /* * LU分解函数 * 参数: * - a: 输入矩阵，n×n的一维数组表示 * - l: 下三角矩阵，n×n的一维数组表示，作为输出参数 * - u: 上三角矩阵，n×n的一维数组表示，作为输出参数 * - n: 矩阵的维度 */ double *a_copy = malloc(sizeof(double) * n * n); memcpy(a_copy, a, sizeof(double) * n * n); // LU分解的第一步：计算下三角矩阵L和上三角矩阵U for (int k = 0; k &lt; n; k++) &#123; // 计算下三角矩阵L的第k列（不包括对角线元素） for (int i = k + 1; i &lt; n; i++) &#123; a[i * n + k] = a[i * n + k] / a[k * n + k]; // 计算L的元素值 &#125; // 计算上三角矩阵U的第k行和第k列（包括对角线元素） for (int i = k + 1; i &lt; n; i++) &#123; for (int j = k + 1; j &lt; n; j++) &#123; a[i * n + j] = a[i * n + j] - a[i * n + k] * a[k * n + j]; // 计算U的元素值 &#125; &#125; &#125; // 构建下三角矩阵L和上三角矩阵U #pragma omp parallel for for (int i = 0; i &lt; n; i++) &#123; #pragma omp parallel for for (int j = 0; j &lt; n; j++) &#123; if (j &lt; i) &#123; l[i * n + j] = a[i * n + j]; // L的元素值为a中对应位置的值 &#125; else &#123; u[i * n + j] = a[i * n + j]; // U的元素值为a中对应位置的值 &#125; &#125; l[i * n + i] = 1.0; // L的对角线元素为1 &#125; memcpy(a, a_copy, sizeof(double) * n * n); free(a_copy);&#125; 计时框架12345678910111213141516171819202122232425262728293031323334353637383940414243444546int main() &#123; srand(time(0)); int batchSize = 100; // 测试批量大小 int n = 200; // 矩阵维度 clock_t whole_time = 0; for (int batch = 0; batch &lt; batchSize; batch++) &#123; // 生成随机矩阵A double* a = (double*)calloc(n * n, sizeof(double)); double* l = (double*)malloc(n * n * sizeof(double)); double* u = (double*)malloc(n * n * sizeof(double)); for (int i = 0; i &lt; n * n; i++) &#123; int row = i / n; int col = i % n; l[i] = rand() % 1000 + 1; // 生成0到99之间的随机数 u[i] = rand() % 1000 + 1; // 生成0到99之间的随机数 if (row == col) l[i] = 1; if (row &lt; col) l[i] = 0; if (row &gt; col) u[i] = 0; &#125; for (size_t i = 0; i &lt; n; i++) &#123; for (size_t j = 0; j &lt; n; j++) &#123; for (size_t k = 0; k &lt; n; k++) &#123; a[i * n + j] += l[i * n + k] * u[k * n + j]; &#125; &#125; &#125; // 分配内存存储结果矩阵L和U // 进行LU分解 clock_t lu_start_time = clock(); // 真正的运算地方 luDecomposition(a, l, u, n); clock_t lu_end_time = clock(); whole_time += lu_end_time - lu_start_time; // 检验分解是否正确，如果不正确，算法也就失去了意义 assert(verifyLU(a, l, u, n)); // 释放内存 free(a); free(l); free(u); &#125; printf(&quot;whole lu time: %lf seconds\\n&quot;, 1.0 * whole_time / CLOCKS_PER_SEC); return 0;&#125; 结果分析与比较经过一番运行，我们发现运行耗时减少了不少： 优化后的代码通过使用OpenMP并行化指令，将计算下三角矩阵L和上三角矩阵U的过程并行化，从而显著提高了运行速度。通过在并行区域内使用独立的#pragma omp for指令，我们成功解决了原始代码中嵌套并行指令的问题。 通过并行化循环，我们能够利用多个线程同时执行迭代操作，充分发挥多核处理器的计算能力。这种优化特别适用于具有大规模矩阵的LU分解操作，因为并行化可以将计算负载分配给多个处理单元，从而加速计算过程。 需要注意的是，在使用OpenMP并行化指令时，我们需要考虑共享数据的访问和可能的竞态条件。如果多个线程同时访问和修改相同的数据，可能会导致错误的结果。在本例中，通过将#pragma omp parallel放置在两个独立的#pragma omp for之外，我们确保了每个线程独立地访问和修改数据，避免了竞态条件的问题。 通过优化代码，我们能够更好地利用计算资源，提高程序的性能。这对于需要处理大规模数据和复杂计算任务的应用程序尤为重要。然而，要确保正确性，我们需要仔细考虑并行化操作对数据一致性的影响，并确保适当的同步机制和数据访问策略。 通过合理地使用并行化技术，我们可以显著提高程序的运行速度，从而更高效地完成计算任务。这为处理大规模数据和复杂计算问题的应用程序提供了有力的工具，促进了科学研究和工程实践的发展。","categories":[],"tags":[]},{"title":"3月21日","slug":"3月21日","date":"2023-07-23T14:07:56.502Z","updated":"2023-07-27T15:43:06.547Z","comments":true,"path":"2023/3月21日/","link":"","permalink":"http://example.com/2023/3%E6%9C%8821%E6%97%A5/","excerpt":"","text":"今天一天的学习下来，我似乎又陷入了某种泥潭。首先让我来回顾一下今天的学习历程： ​ 早上看的CSAPP电子书，里面用的是x86汇编，而我的电脑A是arm架构，所以我登录了我租赁的tencent cloud服务器，诚然，这个服务器能满足我的需求，但是有两个问题：1. 响应速度较慢（因为毕竟是联网，肯定没在本机跑的系统快）2. gdb有某个难以定位的问题。​ 这两个问题让我着魔，虽然我有一台x86的电脑B，但由于是游戏本不方便携带，我固执地想在A上优雅地完成所有的事。于是我打开了我很久未开启的parallel虚拟机，20分钟后，我放弃了（原因是parallel不能换架构），我又花时间试了试qemu，发现其文档实在难看懂，又放弃了。这时候，我在反复浏览网页与阅读电子书的过程中已经缓慢的磨完了第三章（由于不专心，效率并不高）。​ 上午已经过去了。吃完饭后，我又转到CSAPP lab上面去了，我看了看第一个data lab，搜了搜相关资料，发现有个装docker的实践，由于之前就想认真地学下docker，我便照着资料做了一遍，中途遇到了很多问题，又搜索了很多网站，花了大概几个小时吧。但是终究没有解决docker容器的apt下载的网络问题。​ 我今天是想学CSAPP的，结果学了什么？看了无数网站，遇到了无数问题，人已经麻了。现在已经六点了。而我做的事确实也少得可怜，我因此愤恨且坚决地说：干脆用电脑B算了，免得瞎折腾。 这种事情发生了无数次，我无数次地遇到难解的问题从而陷入网页的洪流中，无法自拔，耗费了大量的时间却找不到答案。 其他人有遇到过这种问题吗？如果有，又是什么导致的效率低下？ 想了想，我觉得以后可以分别在思想上和行动上来缓解这个问题。 思想上： 仔细阅读报错代码，学会看log日志定位问题，尝试自己解决。 优先查询中文网站，如果没有结果，则查询英文网站。注意，浏览网站应该慢一些，尤其是英文网站。 也许应该把问题放一放？ 行动上： 听一听音乐缓解一下 出去走一走，理顺思路 详细地记录当前的问题，留在之后解决。也就是TODO list。这很重要，“TODO list以后要记得看”也很重要。","categories":[],"tags":[]}],"categories":[],"tags":[]}